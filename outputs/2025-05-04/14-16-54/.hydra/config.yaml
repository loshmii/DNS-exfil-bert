tokenizer:
  alphabet: abcdefghijklmnopqrstuvwxyz0123456789-._
  vocab_size: 8000
  pad_token: '[PAD]'
  unk_token: '[UNK]'
  cls_token: '[CLS]'
  sep_token: '[SEP]'
  mask_token: '[MASK]'
  max_length: 256
  padding: true
  truncation: true
model:
  type: mbert
training:
  tokenizer:
    training_files:
    - ${hydra:runtime.cwd}/data/processed/train.txt
    - ${hydra:runtime.cwd}/data/processed/val.txt
    - ${hydra:runtime.cwd}/data/processed/test.txt
    output_dir: ${hydra:runtime.cwd}/artifacts/tokenizer/bpe/bpe8k
